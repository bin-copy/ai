import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
dataset_path = r'E:/TYCS_527_AI/OnlineBusinessCustomers.csv'
collected_dataset = pd.read_csv(dataset_path)
# Check for non-numeric columns and convert them if necessary
print("Data Types of Columns:\n", collected_dataset.dtypes)
# Identify categorical columns (non-numeric) and convert them to numeric using 
LabelEncoder
categorical_columns = collected_dataset.select_dtypes(include=['object']).columns
# Initialize LabelEncoder
label_encoder = LabelEncoder()
# Apply LabelEncoder to each categorical column
for col in categorical_columns:
 collected_dataset[col] = label_encoder.fit_transform(collected_dataset[col])
# Verify that all columns are now numeric
print("\nData Types after Label Encoding:\n", collected_dataset.dtypes)
# Select only numeric columns for clustering
# Replace [3, 4] with the actual numeric columns you want to use (e.g., Income and Spending Score)
X = collected_dataset.iloc[:, [3, 4]].values
# Use the Elbow Method to find the optimal number of clusters
wcss = []
for i in range(1, 11):
 kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, 
random_state=0)
 kmeans.fit(X)
 wcss.append(kmeans.inertia_)
# Plot the Elbow Method graph
plt.plot(range(1, 11), wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()
# Apply the KMeans clustering model to the dataset (using 5 clusters as an example)
kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, 
random_state=0)
y_kmeans = kmeans.fit_predict(X)
# Visualize the Clusters (for 2-D clustering)
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s=100, c='red', label='Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s=100, c='blue', label='Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s=100, c='green', label='Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s=100, c='cyan', label='Cluster 4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s=100, c='magenta', label='Cluster 5')
# Plot the centroids
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
 s=300, c='yellow', label='Centroids')
# Add labels and legend
plt.title('Clusters of Online Business Customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1–100)')
plt.legend()
plt.show()
# Visualize the Clusters with custom category names
plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s=100, c='red', label='Careful')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s=100, c='blue', label='Standard')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s=100, c='green', label='Target')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s=100, c='cyan', label='Careless')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s=100, c='magenta', label='Sensible')
# Plot the centroids again
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
 s=300, c='yellow', label='Centroids')
# Add labels and legend
plt.title('Clusters of Online Business Customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1–100)')
plt.legend()
plt.show()
